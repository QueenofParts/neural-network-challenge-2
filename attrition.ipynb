{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alIIEHibGc3M"
      },
      "source": [
        "## Part 1: Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "6eDUJ4NtGc3P",
        "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#  Import and read the attrition data\n",
        "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
        "attrition_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g22aQSY4Gc3Q",
        "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
      },
      "outputs": [],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "attrition_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50vMgBEnJbfM"
      },
      "outputs": [],
      "source": [
        "# Create y_df with the Attrition and Department columns\n",
        "y_df = attrition_df[['Attrition', 'Department']]\n",
        "y_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Virka0zLGc3R",
        "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
      },
      "outputs": [],
      "source": [
        "# Create a list of at least 10 column names to use as X data\n",
        "selected_columns = ['Age', 'BusinessTravel', 'DistanceFromHome', 'PerformanceRating', 'HourlyRate', 'JobSatisfaction', 'WorkLifeBalance', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'RelationshipSatisfaction']\n",
        "\n",
        "# Create X_df using your selected columns\n",
        "X_df = attrition_df[selected_columns]\n",
        "\n",
        "# Show the data types for X_df\n",
        "X_df.dtypes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaJfdOGUMHMR"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, random_state=78)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYubUJqiLCSp",
        "outputId": "53f31721-571c-4c94-d13e-25a715749593"
      },
      "outputs": [],
      "source": [
        "# Convert your X data to numeric data types however you see fit\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test = pd.get_dummies(X_test)\n",
        "# Add new code cells as necessary\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWA-aIA5Gc3T"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler to the training data\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the training and testing data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z0Mky8vQSz4",
        "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Department column\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "dept_enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "department_enc = dept_enc.fit(y_train['Department'].values.reshape(-1, 1))\n",
        "\n",
        "# Create two new variables by applying the encoder\n",
        "y_train_dept_enc = department_enc.transform(y_train['Department'].values.reshape(-1, 1))\n",
        "y_test_dept_enc = department_enc.transform(y_test['Department'].values.reshape(-1, 1))\n",
        "\n",
        "# to the training and testing data, respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G4DSpvFRrk4",
        "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Attrition column\n",
        "att_enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "attrition_enc = att_enc.fit(y_train['Attrition'].values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# Create two new variables by applying the encoder\n",
        "y_train_attr_enc = attrition_enc.transform(y_train['Attrition'].values.reshape(-1, 1))\n",
        "y_test_attr_enc = attrition_enc.transform(y_test['Attrition'].values.reshape(-1, 1))\n",
        "# to the training and testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykNmu_WWGc3T"
      },
      "source": [
        "## Create, Compile, and Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUptZqmSGc3T"
      },
      "outputs": [],
      "source": [
        "# Find the number of columns in the X training data\n",
        "input_features = len(X_train_scaled[0])\n",
        "\n",
        "# Create the input layer\n",
        "inputs = layers.Input(shape=(input_features,))\n",
        "# Add the first hidden layer\n",
        "hidden_layer_1 = layers.Dense(units=8, activation='relu')(inputs)\n",
        "# Add the second hidden layer\n",
        "hidden_layer_2 = layers.Dense(units=8, activation='relu')(hidden_layer_1)\n",
        "\n",
        "# Create at least two shared layers\n",
        "shared_layer_1 = layers.Dense(units=8, activation='relu')(hidden_layer_2)\n",
        "shared_layer_2 = layers.Dense(units=8, activation='relu')(shared_layer_1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JukjTm2yTEqd"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Department\n",
        "department_branch = layers.Dense(units=8, activation='relu')(shared_layer_2)\n",
        "department_output = layers.Dense(units=3, activation='softmax', name='Department')(department_branch)\n",
        "\n",
        "# with a hidden layer and an output layer\n",
        "# Create the hidden layer\n",
        "hidden_layer_3 = layers.Dense(units=8, activation='relu')(shared_layer_2)\n",
        "\n",
        "# Create the output layer\n",
        "output = layers.Dense(units=2, activation='softmax', name='Department')(hidden_layer_3)\n",
        "\n",
        "# Create a branch for Attrition\n",
        "department_branch_branch = layers.Dense(units=8, activation='relu')(shared_layer_2)\n",
        "department_output = layers.Dense(units=2, activation='softmax', name='Department')(department_branch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OqhUiOJUBkR"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Attrition\n",
        "attrition_branch = layers.Dense(units=8, activation='relu')(shared_layer_2)\n",
        "attrition_output = layers.Dense(units=2, activation='softmax', name='Attrition')(attrition_branch)\n",
        "\n",
        "# with a hidden layer and an output layer\n",
        "# Create the hidden layer\n",
        "hidden_layer_3 = layers.Dense(units=8, activation='relu')(shared_layer_2)\n",
        "\n",
        "# Create the output layer\n",
        "output = layers.Dense(units=2, activation='softmax', name='Attrition')(hidden_layer_3)\n",
        "\n",
        "# Create a model with the layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twmuejdxGc3T",
        "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
      },
      "outputs": [],
      "source": [
        "# Define the output layers\n",
        "department_hidden = layers.Dense(32, activation='relu', name='department_hidden')(inputs)\n",
        "department_output = layers.Dense(y_train_dept_enc.shape[1], activation='sigmoid', name='department_output')(department_hidden)\n",
        "\n",
        "attrition_hidden = layers.Dense(32, activation='relu', name='attrition_hidden')(inputs)   \n",
        "attrition_output = layers.Dense(y_train_attr_enc.shape[1], activation='sigmoid', name='attrition_output')(attrition_hidden)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=[department_output, attrition_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss = {'department_output': 'categorical_crossentropy',\n",
        "                    'attrition_output': 'binary_crossentropy'},\n",
        "              metrics= {\n",
        "                  'department_output': 'accuracy',\n",
        "                  'attrition_output': 'accuracy'\n",
        "              \n",
        "              })\n",
        "\n",
        "# Fit the model to the training data\n",
        "\n",
        "\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8oGy0dpGc3U",
        "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(X_train_scaled, {'department_output': y_train_dept_enc, 'attrition_output': y_train_attr_enc},\n",
        "          epochs=100, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsMoaQlgGc3U",
        "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model with the testing data\n",
        "test_results= model.evaluate(X_test_scaled, {'department_output': y_test_dept_enc, 'attrition_output': y_test_attr_enc})\n",
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlCtlHi0Vt54",
        "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
      },
      "outputs": [],
      "source": [
        "# Print the accuracy for both department and attrition\n",
        "print(f\"Department Accuracy: {test_results[2]}\")  \n",
        "print(f\"Attrition Accuracy: {test_results[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGSyfsZfWOQM"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In the provided space below, briefly answer the following questions.\n",
        "\n",
        "1. Is accuracy the best metric to use on this data? Why or why not?\n",
        "\n",
        "2. What activation functions did you choose for your output layers, and why?\n",
        "\n",
        "3. Can you name a few ways that this model might be improved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9SLpFnWvbF"
      },
      "source": [
        "YOUR ANSWERS HERE\n",
        "\n",
        "1. The data seems to be inmablanced which means the F one score or balanced accuracy would be better.\n",
        "2. I have tried relu, sigmoid and softmax. Relu worked for the hidden layers, I used softmax and sigmoid for the output layers.\n",
        "3. Including more columns, adding more layers, finding more training data or experimenting with activation functions could improve tis model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
